<?xml version="1.0" encoding="UTF-8" standalone="no"?><configuration>
<property><name>mapreduce.job.ubertask.enable</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.max-completed-applications</name><value>10000</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.delayed.delegation-token.removal-interval-ms</name><value>30000</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.client.submit.file.replication</name><value>10</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.container-manager.thread-count</name><value>20</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>mapred.queue.default.acl-administer-jobs</name><value>*</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.image.transfer.bandwidthPerSec</name><value>0</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.cache.files.visibilities</name><value>true,true</value><source>programatically</source><source>job.xml</source></property>
<property><name>gridmix.output.directory</name><value>hdfs://localhost:55254/gridmix</value><source>from command line</source><source>job.xml</source></property>
<property><name>dfs.block.access.token.lifetime</name><value>600</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.recovery.enabled</name><value>false</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.am.max-retries</name><value>1</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>fs.AbstractFileSystem.file.impl</name><value>org.apache.hadoop.fs.local.LocalFs</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.client.completion.pollinterval</name><value>5000</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.ubertask.maxreduces</name><value>1</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.shuffle.memory.limit.percent</name><value>0.25</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.ssl.keystores.factory.class</name><value>org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.http.authentication.kerberos.keytab</name><value>${user.home}/hadoop.keytab</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.keytab</name><value>/etc/krb5.keytab</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>io.seqfile.sorter.recordlimit</name><value>1000000</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>s3.blocksize</name><value>67108864</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.task.io.sort.factor</name><value>10</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.disk-health-checker.interval-ms</name><value>120000</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.working.dir</name><value>hdfs://localhost:55254/user/polzovatel</value><source>because mapreduce.job.working.dir is deprecated</source><source>job.xml</source></property>
<property><name>yarn.admin.acl</name><value>*</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.speculative.speculativecap</name><value>0.1</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.num.checkpoints.retained</name><value>2</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.delegation.token.renew-interval</name><value>86400000</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.resource.memory-mb</name><value>8192</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>io.map.index.interval</name><value>128</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>s3.client-write-packet-size</name><value>65536</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.http-address</name><value>localhost:55255</value><source>because dfs.namenode.http-address is deprecated</source><source>job.xml</source></property>
<property><name>mapreduce.task.files.preserve.failedtasks</name><value>false</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>ha.zookeeper.session-timeout.ms</name><value>5000</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.reduce.class</name><value>org.apache.hadoop.mapred.gridmix.LoadJob$LoadReducer</value><source>because mapreduce.job.reduce.class is deprecated</source><source>job.xml</source></property>
<property><name>mapred.cache.files.visibilities</name><value>true,true</value><source>because mapreduce.job.cache.files.visibilities is deprecated</source><source>job.xml</source></property>
<property><name>hadoop.hdfs.configuration.version</name><value>1</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>s3.replication</name><value>3</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>dfs.datanode.balance.bandwidthPerSec</name><value>1048576</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.shuffle.connect.timeout</name><value>180000</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.tasktracker.host.name</name><value>127.0.0.1</value><source>because dfs.datanode.hostname is deprecated</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.aux-services</name><value>mapreduce.shuffle</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.journalnode.rpc-address</name><value>0.0.0.0:8485</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.ssl.enabled</name><value>false</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.counters.max</name><value>120</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>rpc.engine.org.apache.hadoop.hdfs.protocolPB.RefreshUserMappingsProtocolPB</name><value>org.apache.hadoop.ipc.ProtobufRpcEngine</value><source>programatically</source><source>job.xml</source></property>
<property><name>rpc.engine.org.apache.hadoop.hdfs.protocolPB.RefreshAuthorizationPolicyProtocolPB</name><value>org.apache.hadoop.ipc.ProtobufRpcEngine</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.readahead.bytes</name><value>4193404</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.jobtracker.retirejobs</name><value>false</value><source>because mapreduce.jobtracker.retirejobs is deprecated</source><source>job.xml</source></property>
<property><name>ipc.client.connect.max.retries.on.timeouts</name><value>45</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.complete.cancel.delegation.tokens</name><value>true</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>dfs.client.failover.max.attempts</name><value>15</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.checkpoint.dir</name><value>file:/opt/yahoo/yhadoop-common/hadoop-tools/hadoop-gridmix/build/test/data/dfs/namesecondary1,file:/opt/yahoo/yhadoop-common/hadoop-tools/hadoop-gridmix/build/test/data/dfs/namesecondary2</value><source>because dfs.namenode.checkpoint.dir is deprecated</source><source>job.xml</source></property>
<property><name>dfs.namenode.replication.work.multiplier.per.iteration</name><value>2</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>fs.trash.interval</name><value>0</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.admin.address</name><value>agorshkov-ws.lupus.griddynamics.net:55300</value><source>programatically</source><source>job.xml</source></property>
<property><name>ha.health-monitor.check-interval.ms</name><value>1000</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.outputformat.class</name><value>org.apache.hadoop.mapred.gridmix.GridmixJob$RawBytesOutputFormat</value><source>because mapreduce.job.outputformat.class is deprecated</source><source>job.xml</source></property>
<property><name>hadoop.jetty.logs.serve.aliases</name><value>true</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.http.authentication.kerberos.principal</name><value>HTTP/_HOST@LOCALHOST</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.reduce.shuffle.consumer.plugin.class</name><value>org.apache.hadoop.mapreduce.task.reduce.Shuffle</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>s3native.blocksize</name><value>67108864</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.edits.dir</name><value>${dfs.namenode.name.dir}</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>ha.health-monitor.sleep-after-disconnect.ms</name><value>1000</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.map.class</name><value>org.apache.hadoop.mapred.gridmix.LoadJob$LoadMapper</value><source>because mapreduce.job.map.class is deprecated</source><source>job.xml</source></property>
<property><name>dfs.encrypt.data.transfer</name><value>false</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>dfs.datanode.http.address</name><value>0.0.0.0:50075</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.classpath.files</name><value>hdfs://localhost:55254/user/polzovatel/target/org.apache.hadoop.mapred.gridmix.TestGridmixSubmission-tmpDir/MRAppJar.jar,hdfs://localhost:55254/user/polzovatel/target/org.apache.hadoop.mapred.gridmix.TestGridmixSubmission-tmpDir/hadoop-8261859035580915264.jar</value><source>because mapreduce.job.classpath.files is deprecated</source><source>job.xml</source></property>
<property><name>dfs.namenode.write.stale.datanode.ratio</name><value>0.5f</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>dfs.client.use.datanode.hostname</name><value>false</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.map.cpu.vcores</name><value>1</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>yarn.acl.enable</name><value>true</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.security.instrumentation.requires.admin</name><value>false</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.localizer.fetch.thread-count</name><value>4</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.security.authorization</name><value>false</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>user.name</name><value>polzovatel</value><source>because mapreduce.job.user.name is deprecated</source></property>
<property><name>dfs.client.failover.connection.retries.on.timeouts</name><value>0</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.security.group.mapping.ldap.search.filter.group</name><value>(objectClass=group)</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>rpc.engine.org.apache.hadoop.yarn.server.api.ResourceTrackerPB</name><value>org.apache.hadoop.ipc.ProtobufRpcEngine</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.output.fileoutputformat.compress.codec</name><value>org.apache.hadoop.io.compress.DefaultCodec</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.safemode.extension</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.shuffle.port</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.log.level</name><value>INFO</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>yarn.log-aggregation-enable</name><value>false</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>dfs.datanode.sync.behind.writes</name><value>false</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>dfs.https.server.keystore.resource</name><value>ssl-server.xml</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.security.group.mapping.ldap.search.attr.group.name</name><value>cn</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.replication.min</name><value>1</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>s3native.bytes-per-checksum</name><value>512</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>tfile.fs.output.buffer.size</name><value>262144</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.local-dirs</name><value>${hadoop.tmp.dir}/nm-local-dir</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>rpc.engine.org.apache.hadoop.yarn.api.RMAdminProtocolPB</name><value>org.apache.hadoop.ipc.ProtobufRpcEngine</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.AbstractFileSystem.hdfs.impl</name><value>org.apache.hadoop.fs.Hdfs</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>minimrclientcluster.caller.name</name><value>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.job.map.output.collector.class</name><value>org.apache.hadoop.mapred.MapTask$MapOutputBuffer</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.safemode.min.datanodes</name><value>0</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.security.uid.cache.secs</name><value>14400</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>yarn.is.minicluster</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.https.need-auth</name><value>false</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>dfs.client.https.keystore.resource</name><value>ssl-client.xml</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.max.objects</name><value>0</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.ssl.client.conf</name><value>ssl-client.xml</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.safemode.threshold-pct</name><value>0.999f</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>dfs.blocksize</name><value>134217728</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.scheduler.class</name><value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.reduce.slowstart.completedmaps</name><value>0.05</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.end-notification.retry.attempts</name><value>0</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.inputformat.class</name><value>org.apache.hadoop.mapred.gridmix.LoadJob$LoadInputFormat</value><source>because mapreduce.job.inputformat.class is deprecated</source><source>job.xml</source></property>
<property><name>mapreduce.map.memory.mb</name><value>-1</value><source>because mapreduce.map.memory.mb is deprecated</source><source>job.xml</source></property>
<property><name>mapreduce.job.user.name</name><value>polzovatel</value><source>programatically</source></property>
<property><name>io.native.lib.available</name><value>true</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>dfs.client-write-packet-size</name><value>65536</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.name.dir</name><value>file:/opt/yahoo/yhadoop-common/hadoop-tools/hadoop-gridmix/build/test/data/dfs/name1,file:/opt/yahoo/yhadoop-common/hadoop-tools/hadoop-gridmix/build/test/data/dfs/name2</value><source>because dfs.namenode.name.dir is deprecated</source><source>job.xml</source></property>
<property><name>mapreduce.client.progressmonitor.pollinterval</name><value>1000</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>dfs.ha.log-roll.period</name><value>120</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.input.buffer.percent</name><value>0.0</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.map.output.compress.codec</name><value>org.apache.hadoop.io.compress.DefaultCodec</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.map.skip.proc.count.autoincr</name><value>true</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>dfs.client.failover.sleep.base.millis</name><value>500</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.rpc-address</name><value>localhost:55254</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.directoryscan.threads</name><value>1</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.jobtracker.address</name><value>test</value><source>because mapreduce.jobtracker.address is deprecated</source><source>job.xml</source></property>
<property><name>mapreduce.cluster.local.dir</name><value>${hadoop.tmp.dir}/mapred/local</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.application.attempt.id</name><value>1</value><source>programatically</source></property>
<property><name>dfs.permissions.enabled</name><value>true</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>dfs.support.append</name><value>true</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.shuffle.parallelcopies</name><value>5</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.env-whitelist</name><value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,HADOOP_YARN_HOME</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.maxtaskfailures.per.tracker</name><value>3</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>ipc.client.connection.maxidletime</name><value>10000</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.shuffle.ssl.enabled</name><value>false</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.invalidate.work.pct.per.iteration</name><value>0.32f</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>dfs.blockreport.intervalMsec</name><value>21600000</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>fs.s3.sleepTimeSeconds</name><value>10</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.replication.considerLoad</name><value>true</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>yarn.scheduler.maximum-allocation-vcores</name><value>32</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>dfs.client.block.write.retries</name><value>3</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.ssl.server.conf</name><value>ssl-server.xml</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>rpc.engine.org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB</name><value>org.apache.hadoop.ipc.ProtobufRpcEngine</value><source>programatically</source></property>
<property><name>dfs.namenode.name.dir.restore</name><value>false</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>dfs.datanode.hdfs-blocks-metadata.enabled</name><value>false</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>ha.zookeeper.parent-znode</name><value>/hadoop-ha</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapred.queue.names</name><value>default</value><source>programatically</source><source>job.xml</source></property>
<property><name>io.seqfile.lazydecompress</name><value>true</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>dfs.https.enable</name><value>false</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.merge.inmem.threshold</name><value>1000</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.cache.files.filesizes</name><value>473430,140735</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.input.fileinputformat.split.minsize</name><value>0</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>dfs.replication</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>ipc.client.tcpnodelay</name><value>false</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.map.output.value.class</name><value>org.apache.hadoop.mapred.gridmix.GridmixRecord</value><source>because mapreduce.map.output.value.class is deprecated</source><source>job.xml</source></property>
<property><name>dfs.datanode.hostname</name><value>127.0.0.1</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.accesstime.precision</name><value>3600000</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>s3.stream-buffer-size</name><value>4096</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.task.io.sort.mb</name><value>100</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>gridmix.user.resolve.class</name><value>org.apache.hadoop.mapred.gridmix.EchoUserResolver</value><source>from command line</source><source>job.xml</source></property>
<property><name>io.file.buffer.size</name><value>4096</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.audit.loggers</name><value>default</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.checkpoint.txns</name><value>40000</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.admin-env</name><value>MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.split.metainfo.maxsize</name><value>10000000</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>gridmix.job.original-job-id</name><value>job_job_mock_MOCKJOB000000_0000</value><source>programatically</source><source>job.xml</source></property>
<property><name>rpc.engine.org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolPB</name><value>org.apache.hadoop.ipc.ProtobufRpcEngine</value><source>programatically</source></property>
<property><name>yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms</name><value>1000</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.maxattempts</name><value>4</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>dfs.ha.tail-edits.period</name><value>60</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>rpc.engine.org.apache.hadoop.yarn.api.AMRMProtocolPB</name><value>org.apache.hadoop.ipc.ProtobufRpcEngine</value><source>programatically</source></property>
<property><name>hadoop.security.authentication</name><value>simple</value><source>hdfs-site.xml</source><source>job.xml</source></property>
<property><name>fs.s3.buffer.dir</name><value>${hadoop.tmp.dir}/s3</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.output.group.comparator.class</name><value>org.apache.hadoop.mapred.gridmix.GridmixJob$SpecGroupingComparator</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.am.job.task.listener.thread-count</name><value>30</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.reduces</name><value>1</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.map.sort.spill.percent</name><value>0.80</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>yarn.scheduler.capacity.root.queues</name><value>default</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.file-block-storage-locations.timeout</name><value>60</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>dfs.datanode.drop.cache.behind.writes</name><value>false</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.end-notification.retry.interval</name><value>1000</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.maps</name><value>5</value><source>because mapreduce.job.maps is deprecated</source><source>job.xml</source></property>
<property><name>mapreduce.job.speculative.slownodethreshold</name><value>1.0</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>rpc.engine.org.apache.hadoop.yarn.api.ClientRMProtocolPB</name><value>org.apache.hadoop.ipc.ProtobufRpcEngine</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.block.access.token.enable</name><value>false</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>tfile.fs.input.buffer.size</name><value>262144</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.map.speculative</name><value>true</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>dfs.journalnode.http-address</name><value>0.0.0.0:8480</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.acl-view-job</name><value> </value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.shuffle.retry-delay.max.ms</name><value>60000</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.kerberos.min.seconds.before.relogin</name><value>60</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.map.output.key.class</name><value>org.apache.hadoop.mapred.gridmix.GridmixKey</value><source>because mapreduce.map.output.key.class is deprecated</source><source>job.xml</source></property>
<property><name>yarn.ipc.serializer.type</name><value>protocolbuffers</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.end-notification.max.retry.interval</name><value>5000</value><source>mapred-default.xml</source></property>
<property><name>ftp.blocksize</name><value>67108864</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>dfs.datanode.data.dir</name><value>file:/opt/yahoo/yhadoop-common/hadoop-tools/hadoop-gridmix/build/test/data/dfs/data/data1,file:/opt/yahoo/yhadoop-common/hadoop-tools/hadoop-gridmix/build/test/data/dfs/data/data2</value><source>programatically</source><source>job.xml</source></property>
<property><name>ha.failover-controller.cli-check.rpc-timeout.ms</name><value>20000</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.max.extra.edits.segments.retained</name><value>10000</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.replication.interval</name><value>3</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>gridmix.job-submission.default-queue</name><value>default</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.https-address</name><value>0.0.0.0:50470</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.task.skip.start.attempts</name><value>2</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>dfs.ha.automatic-failover.enabled</name><value>false</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>ipc.client.kill.max</name><value>10</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.linux-container-executor.cgroups.mount</name><value>false</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.keytab</name><value>/etc/security/keytab/jhs.service.keytab</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.linux-container-executor.cgroups.hierarchy</name><value>/hadoop-yarn</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>dfs.client.failover.sleep.max.millis</name><value>15000</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.end-notification.max.attempts</name><value>5</value><source>mapred-default.xml</source></property>
<property><name>mapreduce.task.tmp.dir</name><value>./tmp</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>dfs.default.chunk.view.size</name><value>32768</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.memory.mb</name><value>-1</value><source>because mapreduce.reduce.memory.mb is deprecated</source><source>job.xml</source></property>
<property><name>hadoop.http.filter.initializers</name><value>org.apache.hadoop.yarn.server.webproxy.amfilter.AmFilterInitializer</value><source>programatically</source><source>job.xml</source></property>
<property><name>gridmix.job.seq</name><value>0</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.failed.volumes.tolerated</name><value>0</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.http.authentication.type</name><value>simple</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>dfs.datanode.data.dir.perm</name><value>700</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.client.thread-count</name><value>50</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>ipc.server.listen.queue.size</name><value>128</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.skip.maxgroups</name><value>0</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>file.stream-buffer-size</name><value>4096</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>gridmix.job-submission.policy</name><value>REPLAY</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.pseudo.impl</name><value>org.apache.hadoop.mapred.gridmix.PseudoLocalFs</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.fs-limits.max-directory-items</name><value>0</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.store.class</name><value>org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>io.mapfile.bloom.size</name><value>1048576</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.container-executor.class</name><value>org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.map.maxattempts</name><value>4</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>yarn.log-aggregation.retain-seconds</name><value>-1</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.am.job.committer.cancel-timeout</name><value>60000</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>ftp.replication</name><value>3</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.health-checker.script.timeout-ms</name><value>1200000</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.address</name><value>agorshkov-ws.lupus.griddynamics.net:55386</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.dns.nameserver</name><value>default</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.application.classpath</name><value>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*,$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.log.retain-seconds</name><value>10800</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>mapred.child.java.opts</name><value>-Xmx200m</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.replication.max</name><value>512</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>map.sort.class</name><value>org.apache.hadoop.util.QuickSort</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>dfs.stream-buffer-size</name><value>4096</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.backup.address</name><value>0.0.0.0:50100</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.util.hash.type</name><value>murmur</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>dfs.block.access.key.update.interval</name><value>600</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>dfs.datanode.use.datanode.hostname</name><value>false</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>dfs.datanode.dns.interface</name><value>default</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.skip.proc.count.autoincr</name><value>true</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.backup.http-address</name><value>0.0.0.0:50105</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.container-monitor.interval-ms</name><value>3000</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>mapred.reducer.new-api</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.disk-health-checker.min-healthy-disks</name><value>0.25</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>ha.zookeeper.acl</name><value>world:anyone:rwcda</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.sleep-delay-before-sigkill.ms</name><value>250</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.dir</name><value>/tmp/hadoop-yarn/staging/polzovatel/.staging/job_1359639575783_0002</value><source>programatically</source><source>job.xml</source></property>
<property><name>io.map.index.skip</name><value>0</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.check.stale.datanode</name><value>false</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>net.topology.node.switch.mapping.impl</name><value>org.apache.hadoop.net.StaticMapping</value><source>programatically</source><source>job.xml</source></property>
<property><name>rpc.engine.org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolPB</name><value>org.apache.hadoop.ipc.ProtobufRpcEngine</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.s3.maxRetries</name><value>4</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.logging.level</name><value>info</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>ha.failover-controller.new-active.rpc-timeout.ms</name><value>60000</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>s3native.client-write-packet-size</name><value>65536</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>test.fs.s3.name</name><value>s3:///</value><source>core-site.xml</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.amliveliness-monitor.interval-ms</name><value>1000</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.http.staticuser.user</name><value>dr.who</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.speculative</name><value>true</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.client.output.filter</name><value>FAILED</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.ifile.readahead.bytes</name><value>4194304</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.task.userlog.limit.kb</name><value>0</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.http.authentication.simple.anonymous.allowed</name><value>true</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.fuse.timer.period</name><value>5</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.num.extra.edits.retained</name><value>1000000</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.classloader.system.classes</name><value>java.,javax.,org.apache.commons.logging.,org.apache.log4j.,org.apache.hadoop.</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.rpc.socket.factory.class.default</name><value>org.apache.hadoop.net.StandardSocketFactory</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.submithostname</name><value>agorshkov-ws.lupus.griddynamics.net</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.handler.count</name><value>10</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>gridmix.min.file.size</name><value>0</value><source>from command line</source><source>job.xml</source></property>
<property><name>mapreduce.job.output.key.comparator.class</name><value>org.apache.hadoop.mapred.gridmix.LoadJob$LoadSortComparator</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.automatic.close</name><value>false</value><source>programatically</source></property>
<property><name>mapreduce.job.submithostaddress</name><value>172.18.140.21</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.directoryscan.interval</name><value>21600</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.address</name><value>agorshkov-ws.lupus.griddynamics.net:55299</value><source>programatically</source><source>job.xml</source></property>
<property><name>gridmix.compression-emulation.enable</name><value>false</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.client.file-block-storage-locations.num-threads</name><value>10</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.health-checker.interval-ms</name><value>600000</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs</name><value>86400</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>rpc.engine.org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolPB</name><value>org.apache.hadoop.ipc.ProtobufRpcEngine</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.markreset.buffer.percent</name><value>0.0</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.map.log.level</name><value>INFO</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.localizer.address</name><value>0.0.0.0:8040</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>dfs.bytes-per-checksum</name><value>512</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.avoid.write.stale.datanode</name><value>false</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>ftp.stream-buffer-size</name><value>4096</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.keytab</name><value>/etc/krb5.keytab</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>ha.health-monitor.rpc-timeout.ms</name><value>45000</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.output.fileoutputformat.outputdir</name><value>hdfs://localhost:55254/gridmix/0</value><source>because mapreduce.output.fileoutputformat.outputdir is deprecated</source><source>job.xml</source></property>
<property><name>hadoop.security.group.mapping.ldap.search.attr.member</name><value>member</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>dfs.blockreport.initialDelay</name><value>0</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.classloader</name><value>false</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nm.liveness-monitor.expiry-interval-ms</name><value>600000</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.http.authentication.token.validity</name><value>36000</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.resource.cpu-cores</name><value>8</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.vcores-pcores-ratio</name><value>2</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.delegation.token.max-lifetime</name><value>604800000</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.hdfs-servers</name><value>${fs.defaultFS}</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>s3native.replication</name><value>3</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>rpc.engine.org.apache.hadoop.ipc.ProtocolMetaInfoPB</name><value>org.apache.hadoop.ipc.ProtobufRpcEngine</value><source>programatically</source></property>
<property><name>dfs.heartbeat.interval</name><value>3</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.localizer.client.thread-count</name><value>5</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.container.liveness-monitor.interval-ms</name><value>600000</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>dfs.ha.fencing.ssh.connect-timeout</name><value>30000</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>yarn.am.liveness-monitor.expiry-interval-ms</name><value>600000</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>net.topology.impl</name><value>org.apache.hadoop.net.NetworkTopology</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.task.profile</name><value>false</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.linux-container-executor.resources-handler.class</name><value>org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.webapp.address</name><value>agorshkov-ws.lupus.griddynamics.net:55385</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.ipc.rpc.class</name><value>org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>ha.failover-controller.graceful-fence.rpc-timeout.ms</name><value>5000</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.name</name><value>GRIDMIX000000</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.application-tokens.master-key-rolling-interval-secs</name><value>86400</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.ubertask.maxmaps</name><value>9</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.cache.files</name><value>hdfs://localhost:55254/user/polzovatel/target/org.apache.hadoop.mapred.gridmix.TestGridmixSubmission-tmpDir/MRAppJar.jar,hdfs://localhost:55254/user/polzovatel/target/org.apache.hadoop.mapred.gridmix.TestGridmixSubmission-tmpDir/hadoop-8261859035580915264.jar</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.scheduler.maximum-allocation-mb</name><value>8192</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.heartbeat.interval-ms</name><value>1000</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>fs.ftp.password.localhost</name><value>password</value><source>core-site.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.secondary.http-address</name><value>0.0.0.0:50090</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.task.timeout</name><value>600000</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.framework.name</name><value>yarn</value><source>programatically</source><source>job.xml</source></property>
<property><name>ipc.client.idlethreshold</name><value>4000</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>ipc.server.tcpnodelay</name><value>false</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>ftp.bytes-per-checksum</name><value>512</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.stale.datanode.interval</name><value>30000</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>s3.bytes-per-checksum</name><value>512</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.speculative.slowtaskthreshold</name><value>1.0</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.localizer.cache.target-size-mb</name><value>10240</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.remote-app-log-dir</name><value>/tmp/logs</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>fs.s3.block.size</name><value>128</value><source>core-site.xml</source><source>job.xml</source></property>
<property><name>dfs.client.failover.connection.retries</name><value>0</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.queuename</name><value>default</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.scheduler.minimum-allocation-mb</name><value>1024</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.rpc.protection</name><value>authentication</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.cache.files.timestamps</name><value>1359639575508,1359639575598</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.client-am.ipc.max-retries</name><value>1</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>dfs.secondary.namenode.kerberos.internal.spnego.principal</name><value>${dfs.web.authentication.kerberos.principal}</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>ftp.client-write-packet-size</name><value>65536</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>minimrclientcluster.nodemanagers.number</name><value>2</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.address</name><value>0.0.0.0:0</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>fs.defaultFS</name><value>hdfs://localhost:55254</value><source>because fs.defaultFS is deprecated</source><source>job.xml</source></property>
<property><name>gridmix.job.original-job-name</name><value>MOCKJOB000000</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.task.merge.progress.records</name><value>10000</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.scheduler.client.thread-count</name><value>50</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>file.client-write-packet-size</name><value>65536</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.partitioner.class</name><value>org.apache.hadoop.mapred.gridmix.GridmixJob$DraftPartitioner</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.cpu.vcores</name><value>1</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.delete.thread-count</name><value>4</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.scheduler.address</name><value>agorshkov-ws.lupus.griddynamics.net:55298</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.trash.checkpoint.interval</name><value>0</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.http.authentication.signature.secret.file</name><value>${user.home}/hadoop-http-auth-signature-secret</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>s3native.stream-buffer-size</name><value>4096</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.shuffle.read.timeout</name><value>180000</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.am.command-opts</name><value>-Xmx1024m</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.admin.user.env</name><value>LD_LIBRARY_PATH=$HADOOP_COMMON_HOME/lib/native</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.fs.rm-state-store.uri</name><value>${hadoop.tmp.dir}/yarn/system/rmstore</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.checkpoint.edits.dir</name><value>${dfs.namenode.checkpoint.dir}</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.local.clientfactory.class.name</name><value>org.apache.hadoop.mapred.LocalClientFactory</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>fs.permissions.umask-mode</name><value>000</value><source>programatically</source><source>job.xml</source></property>
<property><name>hadoop.common.configuration.version</name><value>3.0.0</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.output.fileoutputformat.compress.type</name><value>RECORD</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.security.group.mapping.ldap.ssl</name><value>false</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.ifile.readahead</name><value>true</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>io.serializations</name><value>org.apache.hadoop.io.serializer.WritableSerialization,org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization,org.apache.hadoop.io.serializer.avro.AvroReflectSerialization</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name><value>org.apache.hadoop.mapred.ShuffleHandler</value><source>programatically</source><source>job.xml</source></property>
<property><name>fs.df.interval</name><value>60000</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.shuffle.input.buffer.percent</name><value>0.70</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>io.seqfile.compress.blocksize</name><value>1000000</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>ipc.client.connect.max.retries</name><value>10</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.security.groups.cache.secs</name><value>300</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.delegation.key.update-interval</name><value>86400000</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.process-kill-wait.ms</name><value>2000</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>yarn.application.classpath</name><value>$HADOOP_CONF_DIR,$HADOOP_COMMON_HOME/share/hadoop/common/*,$HADOOP_COMMON_HOME/share/hadoop/common/lib/*,$HADOOP_HDFS_HOME/share/hadoop/hdfs/*,$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*,$HADOOP_YARN_HOME/share/hadoop/yarn/*,$HADOOP_YARN_HOME/share/hadoop/yarn/lib/*</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.client.max-retries</name><value>3</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.log-aggregation.compression-type</name><value>none</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.security.group.mapping.ldap.search.filter.user</name><value>(&amp;(objectClass=user)(sAMAccountName={0}))</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>dfs.image.compress</name><value>false</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.localizer.cache.cleanup.interval-ms</name><value>600000</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>mapred.mapper.new-api</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.kerberos.internal.spnego.principal</name><value>${dfs.web.authentication.kerberos.principal}</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.log-dirs</name><value>${yarn.log.dir}/userlogs</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>fs.s3n.block.size</name><value>67108864</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>fs.ftp.host</name><value>0.0.0.0</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.security.group.mapping</name><value>org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapred.cache.files.filesizes</name><value>473430,140735</value><source>because mapreduce.job.cache.files.filesizes is deprecated</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.am.resource.cpu-vcores</name><value>1</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>gridmix.job-submission.use-queue-in-trace</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.address</name><value>0.0.0.0:50010</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.map.skip.maxrecords</name><value>0</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>dfs.datanode.https.address</name><value>0.0.0.0:50475</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>yarn.scheduler.minimum-allocation-vcores</name><value>1</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>file.replication</name><value>1</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.resource-tracker.address</name><value>agorshkov-ws.lupus.griddynamics.net:55297</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.datanode.drop.cache.behind.reads</name><value>false</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>test.fs.s3n.name</name><value>s3n:///</value><source>core-site.xml</source><source>job.xml</source></property>
<property><name>hadoop.fuse.connection.timeout</name><value>300</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.work.around.non.threadsafe.getpwuid</name><value>false</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.client.genericoptionsparser.used</name><value>true</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.output.fileoutputformat.compress</name><value>false</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.tmp.dir</name><value>build/test</value><source>core-site.xml</source></property>
<property><name>dfs.client.block.write.replace-datanode-on-failure.policy</name><value>DEFAULT</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>fs.ftp.user.localhost</name><value>user</value><source>core-site.xml</source><source>job.xml</source></property>
<property><name>hadoop.kerberos.kinit.command</name><value>kinit</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.committer.setup.cleanup.needed</name><value>true</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>dfs.webhdfs.enabled</name><value>false</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>dfs.datanode.du.reserved</name><value>0</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>yarn.scheduler.capacity.root.default.capacity</name><value>100.0</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.task.profile.reduces</name><value>0-2</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>file.bytes-per-checksum</name><value>512</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>dfs.client.block.write.replace-datanode-on-failure.enable</name><value>true</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.am.job.committer.commit-window</name><value>10000</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.startup</name><value>REGULAR</value><source>programatically</source><source>job.xml</source></property>
<property><name>yarn.dispatcher.exit-on-error</name><value>true</value><source>programatically</source></property>
<property><name>net.topology.script.number.args</name><value>100</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.task.profile.maps</name><value>0-2</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.decommission.interval</name><value>3</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.image.compression.codec</name><value>org.apache.hadoop.io.compress.DefaultCodec</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.webapp.address</name><value>agorshkov-ws.lupus.griddynamics.net:55274</value><source>programatically</source><source>job.xml</source></property>
<property><name>dfs.namenode.support.allow.format</name><value>true</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.ssl.hostname.verifier</name><value>DEFAULT</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.vmem-pmem-ratio</name><value>2.1</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>ipc.client.connect.timeout</name><value>20000</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>rpc.engine.org.apache.hadoop.ha.protocolPB.HAServiceProtocolPB</name><value>org.apache.hadoop.ipc.ProtobufRpcEngine</value><source>programatically</source><source>job.xml</source></property>
<property><name>io.mapfile.bloom.error.rate</name><value>0.005</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.jobhistory.principal</name><value>jhs/_HOST@REALM.TLD</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>dfs.permissions.superusergroup</name><value>supergroup</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.shuffle.ssl.file.buffer.size</name><value>65536</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.cluster.acls.enabled</name><value>false</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.remote-app-log-dir-suffix</name><value>logs</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>ha.failover-controller.graceful-fence.connection.retries</name><value>1</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>ha.health-monitor.connect-retry-interval.ms</name><value>1000</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.checkpoint.check.period</name><value>60</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>io.seqfile.local.dir</name><value>${hadoop.tmp.dir}/io/local</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.am.resource.mb</name><value>1536</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.reduce.shuffle.merge.percent</name><value>0.66</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>tfile.io.chunk.size</name><value>1048576</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>file.blocksize</name><value>67108864</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.nm.liveness-monitor.interval-ms</name><value>1000</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.webapp.address</name><value>0.0.0.0:8042</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>mapreduce.job.acl-modify-job</name><value> </value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>io.skip.checksum.errors</name><value>false</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>yarn.app.mapreduce.am.staging-dir</name><value>/tmp/hadoop-yarn/staging</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.edits.journal-plugin.qjournal</name><value>org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>dfs.datanode.handler.count</name><value>10</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.decommission.nodes.per.interval</name><value>5</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>fs.ftp.host.port</name><value>21</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.checkpoint.period</name><value>3600</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>dfs.namenode.fs-limits.max-component-length</name><value>0</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.admin.client.thread-count</name><value>1</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>fs.AbstractFileSystem.viewfs.impl</name><value>org.apache.hadoop.fs.viewfs.ViewFs</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>yarn.resourcemanager.resource-tracker.client.thread-count</name><value>50</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>rpc.engine.org.apache.hadoop.hdfs.protocolPB.GetUserMappingsProtocolPB</name><value>org.apache.hadoop.ipc.ProtobufRpcEngine</value><source>programatically</source><source>job.xml</source></property>
<property><name>mapreduce.map.output.compress</name><value>false</value><source>mapred-default.xml</source><source>job.xml</source></property>
<property><name>dfs.datanode.ipc.address</name><value>0.0.0.0:50020</value><source>hdfs-default.xml</source><source>job.xml</source></property>
<property><name>yarn.nodemanager.delete.debug-delay-sec</name><value>0</value><source>yarn-default.xml</source><source>job.xml</source></property>
<property><name>hadoop.ssl.require.client.cert</name><value>false</value><source>core-default.xml</source><source>job.xml</source></property>
<property><name>dfs.datanode.max.transfer.threads</name><value>4096</value><source>hdfs-default.xml</source><source>job.xml</source></property>
</configuration>